{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits dataset keys \n",
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print('Digits dataset keys \\n{}'.format(digits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset target name: \n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "shape of dataset: (1797, 64) \n",
      "and target: (1797,)\n",
      "shape of the images: (1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print('dataset target name: \\n{}'.format(digits.target_names))\n",
    "print('shape of dataset: {} \\nand target: {}'.format(digits.data.shape, digits.target.shape))\n",
    "print('shape of the images: {}'.format(digits.images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
      " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
      " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n",
      "[[ 0.  0.  0.  4. 15. 12.  0.  0.]\n",
      " [ 0.  0.  3. 16. 15. 14.  0.  0.]\n",
      " [ 0.  0.  8. 13.  8. 16.  0.  0.]\n",
      " [ 0.  0.  1.  6. 15. 11.  0.  0.]\n",
      " [ 0.  1.  8. 13. 15.  1.  0.  0.]\n",
      " [ 0.  9. 16. 16.  5.  0.  0.  0.]\n",
      " [ 0.  3. 13. 16. 16. 11.  5.  0.]\n",
      " [ 0.  0.  0.  3. 11. 16.  9.  0.]]\n",
      "[[ 0.  0.  7. 15. 13.  1.  0.  0.]\n",
      " [ 0.  8. 13.  6. 15.  4.  0.  0.]\n",
      " [ 0.  2.  1. 13. 13.  0.  0.  0.]\n",
      " [ 0.  0.  2. 15. 11.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. 12. 12.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1. 10.  8.  0.]\n",
      " [ 0.  0.  8.  4.  5. 14.  9.  0.]\n",
      " [ 0.  0.  7. 13. 13.  9.  0.  0.]]\n",
      "[[ 0.  0.  0.  1. 11.  0.  0.  0.]\n",
      " [ 0.  0.  0.  7.  8.  0.  0.  0.]\n",
      " [ 0.  0.  1. 13.  6.  2.  2.  0.]\n",
      " [ 0.  0.  7. 15.  0.  9.  8.  0.]\n",
      " [ 0.  5. 16. 10.  0. 16.  6.  0.]\n",
      " [ 0.  4. 15. 16. 13. 16.  1.  0.]\n",
      " [ 0.  0.  0.  3. 15. 10.  0.  0.]\n",
      " [ 0.  0.  0.  2. 16.  4.  0.  0.]]\n",
      "[[ 0.  0. 12. 10.  0.  0.  0.  0.]\n",
      " [ 0.  0. 14. 16. 16. 14.  0.  0.]\n",
      " [ 0.  0. 13. 16. 15. 10.  1.  0.]\n",
      " [ 0.  0. 11. 16. 16.  7.  0.  0.]\n",
      " [ 0.  0.  0.  4.  7. 16.  7.  0.]\n",
      " [ 0.  0.  0.  0.  4. 16.  9.  0.]\n",
      " [ 0.  0.  5.  4. 12. 16.  4.  0.]\n",
      " [ 0.  0.  9. 16. 16. 10.  0.  0.]]\n",
      "[[ 0.  0.  0. 12. 13.  0.  0.  0.]\n",
      " [ 0.  0.  5. 16.  8.  0.  0.  0.]\n",
      " [ 0.  0. 13. 16.  3.  0.  0.  0.]\n",
      " [ 0.  0. 14. 13.  0.  0.  0.  0.]\n",
      " [ 0.  0. 15. 12.  7.  2.  0.  0.]\n",
      " [ 0.  0. 13. 16. 13. 16.  3.  0.]\n",
      " [ 0.  0.  7. 16. 11. 15.  8.  0.]\n",
      " [ 0.  0.  1.  9. 15. 11.  3.  0.]]\n",
      "[[ 0.  0.  7.  8. 13. 16. 15.  1.]\n",
      " [ 0.  0.  7.  7.  4. 11. 12.  0.]\n",
      " [ 0.  0.  0.  0.  8. 13.  1.  0.]\n",
      " [ 0.  4.  8.  8. 15. 15.  6.  0.]\n",
      " [ 0.  2. 11. 15. 15.  4.  0.  0.]\n",
      " [ 0.  0.  0. 16.  5.  0.  0.  0.]\n",
      " [ 0.  0.  9. 15.  1.  0.  0.  0.]\n",
      " [ 0.  0. 13.  5.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  9. 14.  8.  1.  0.  0.]\n",
      " [ 0.  0. 12. 14. 14. 12.  0.  0.]\n",
      " [ 0.  0.  9. 10.  0. 15.  4.  0.]\n",
      " [ 0.  0.  3. 16. 12. 14.  2.  0.]\n",
      " [ 0.  0.  4. 16. 16.  2.  0.  0.]\n",
      " [ 0.  3. 16.  8. 10. 13.  2.  0.]\n",
      " [ 0.  1. 15.  1.  3. 16.  8.  0.]\n",
      " [ 0.  0. 11. 16. 15. 11.  1.  0.]]\n",
      "[[ 0.  0. 11. 12.  0.  0.  0.  0.]\n",
      " [ 0.  2. 16. 16. 16. 13.  0.  0.]\n",
      " [ 0.  3. 16. 12. 10. 14.  0.  0.]\n",
      " [ 0.  1. 16.  1. 12. 15.  0.  0.]\n",
      " [ 0.  0. 13. 16.  9. 15.  2.  0.]\n",
      " [ 0.  0.  0.  3.  0.  9. 11.  0.]\n",
      " [ 0.  0.  0.  0.  9. 15.  4.  0.]\n",
      " [ 0.  0.  9. 12. 13.  3.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    plt.subplot(2, 10,i + 1)\n",
    "    plt.axis('off')\n",
    "    imside = int(np.sqrt(digits.data[i].shape[0]))\n",
    "    im1 = np.reshape(digits.data[i],(imside,imside))\n",
    "    print(im1)\n",
    "    #plt.imshow(im1, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.imshow(im1)\n",
    "    plt.title(digits.target[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from here we will be using the images. First we should flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data_images = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and target sizes: \n",
      "(1347, 64), (1347,)\n",
      "Test data and target sizes: \n",
      "(450, 64), (450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_images,digits.target)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\\n  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\\n  tol=0.001, verbose=False)\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "#classifier = svm.SVC(gamma=0.001, verbose=True)\n",
    "classifier = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=True)\n",
    "\n",
    "#fit to the training data\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "\"\"\"\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to Now predict the value of the digit on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=True):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        54\n",
      "           1       0.96      1.00      0.98        45\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.97      0.97      0.97        35\n",
      "           4       0.98      1.00      0.99        42\n",
      "           5       0.98      1.00      0.99        49\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.95      0.93      0.94        42\n",
      "           9       0.96      0.92      0.94        49\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "precision is the fraction of relevant instances among the retrieved instances and is defined as:\n",
    "precision = tp / (tp + fp) or (true positives)/(prediced positives)\n",
    "\n",
    "recall is the fraction of relevant instances that have been retrieved over total relevant instances in the image, and is defined as\n",
    "recall = tp / (tp + fn) or (true positives)/(actual positives)\n",
    "Where, tp = true positives, fp = false positives anf fn = false negatives. Recall in this context is also referred to as the true positive rate or sensitivity, and precision is also referred to as positive predictive value (PPV).\n",
    "\n",
    "f1-score: is a measure of a test's accuracy. It considers both the precision and the recall to compute the score. The f1-score can be interpreted as a weighted average of the precision and recall, where an f1-score reaches its best value at 1 and worst at 0.\n",
    "The general formula is: 2.(precision.recall)/(precision+recall)\n",
    "The f1-score regulates bot precision and recall.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
